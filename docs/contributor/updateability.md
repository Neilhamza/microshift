# Upgrading MicroShift

Following document is meant to be a contributor's introduction
to the feature of MicroShift's updateability.

## On-disk artifacts

New on-disk artifacts were added:
- `/var/lib/microshift-backups/`
    - `health.json`
    - backup directories
- `/var/lib/microshift/version`

### `/var/lib/microshift-backups/`

New, additional directory for keeping health and backup related artifacts.
For ostree systems it's a non-configurable directory where backups are created.
For non-ostree systems it's a default (configurable) directory for backups.

#### `health.json` [ostree-only]

Contains information about health of the system.
It's updated by green and red script supplied by MicroShift.

Because MicroShift's healthcheck takes some time to assess the state of the MicroShift,
this file might be updated after couple minutes into system boot.

Schema:
```json
{
    "health": "",
    "deployment_id": "",
    "boot_id": ""
}
```

- `health`: System status according to the greenboot healthchecks.
  - Expected values: `healthy` or `unhealthy`
- `deployment_id`: OSTree deployment ID.
  - Obtained with a command: `rpm-ostree status --json | jq '.deployments[].id'`
- `boot_id`: Boot ID generated by kernel.
  - Obtained with command: `tr -d '-' < /proc/sys/kernel/random/boot_id`.
  - Hyphens are removed to match format used by `journalctl` (see `journalctl --list-boots --reverse`)


#### Backup directories

> Note: Only ostree-based systems perform automated backups and restores.

`/var/lib/microshift-backups/` also stores backups of MicroShift data.
Backups are created by copying data directory with `--reflink`
option to leverage Copy-on-Write functionality.

Naming schema of backup directories: `deployment-id_boot-id[_unhealthy]`.

Suffix `_unhealthy` is used to mark backups of unhealthy systems.
These backups are performed when all existing metadata suggests that it is expected
that MicroShift should wipe the data and start from clean state
(for example "FDO" scenario where unhealthy deployment leaves stale data).

### `/var/lib/microshift/version`

TODO

Schema:
```
MAJOR.MINOR.PATCH
```

All of MAJOR, MINOR, and PATCH are unsigned integers.
For example: `4.14.0`

## Greenboot

TODO: Difference between ostree and normal systems

- `/etc/greenboot/green.d/40_microshift_set_healthy.sh`
- `/etc/greenboot/red.d/40_microshift_set_unhealthy.sh`
- `/etc/greenboot/red.d/40_microshift_pre_rollback.sh`

## (rpm-)ostree [ostree-only]

TODO

### `rpm-ostree` vs `ostree`

TODO

### Commits and deployments

TODO

<!--
ostree     -> commits
rpm-ostree -> deployments

Deployment is a commit with a boot entry.
-->

## Useful `ostree` commands

TODO

## Useful `rpm-ostree` commands

TODO

## Grub [ostree]

TODO
- boot_counter and boot_success

### grub-boot-success.timer

## Implementation

Upgradeability introduces following features that run in following order:
- backup management,
- version metadata management,
- Kubernetes storage migration.

These three areas are mostly separate, but backup management
may inspect version metadata to handle some corner cases.
Backup management and version metadata management run
before MicroShift attempts to start all the components and cluster itself.
Storage migration runs when cluster is up and running 
(and in 10 minutes intervals afterwards) because it
requires runtime components to correctly perform its task.

### Automated backup management [ostree-only]

It runs very close to the start of MicroShift's `run` command.

It checks for existence of `/run/ostree-booted` file.
If the file is not present, it is assumed that the system is regular RPM based
and this stage is skipped without an error.

#### Handling unusual scenarios

Then, procedure checks existence of three on-disk artifacts:
- `/var/lib/microshift` (ignores `.nodename`[0]) - referred to as data below
- `/var/lib/microshift/version`
- `/var/lib/microshift-backups/health.json`

[0] `.nodename` might be created by the "effective config generation" phase
which happens before the prerun. This can create `.nodename` and result
in `/var/lib/microshift` being present but, beside that one file, empty.

##### `/var/lib/microshift` (data) does not exist

> Lack of `/var/lib/microshift` implies that `/var/lib/microshift/version` does not exist.

If both data and `health.json` are missing, then we assume it's a first run of MicroShift.

If data does not exist but `health.json` is present, it means that MicroShift ran on the system already.
Perhaps it was unhealthy and admin decided to delete the data dir to try clean start.
In such case MicroShift will inspect `health.json` and depending of value of `health`:
- `healthy` - last boot with MicroShift was OK, but there is no data?
  There's nothing to back up, so MicroShift will continue start up.
- `unhealthy` - MicroShift will look for a healthy backup for currently
  booted deployment 
  - if backup is found, it'll be restored
  - if there is no backup to restore from, MicroShift will continue start up (no data = clean start).


##### Data exists, but `version` does not

If `health.json` exists, then what could have happened is failed upgrade from 4.13,
resulting in system rollback, followed by admin's manual intervention by removing
`/var/lib/microshift`, but keeping `/var/lib/microshift-backups`.

That's why, ignoring completely existence of `health.json`,
if `/var/lib/microshift` exists but `version` file does not,
MicroShift will treat the data as an upgrade from MicroShift 4.13 
(because it's the last release not featuring that file), create a backup
named `4.13` and proceed with the start up.

> TODO: if system rolls back to 4.13 deployment, and an upgrade is attempted again
> without manually deleting `4.13` backup after manually restoring it,
> MicroShift will fail to make a backup and exit with an error
> (because backup with such name already exists).
> It feels like we should handle this more gracefully.

##### Both data and `version` exist, but `health.json` does not

On the very first run of a deployment featuring MicroShift,
none of the `/var/lib/microshift` or `/var/lib/microshift-backups` exist.
In such case `health.json` will exists only after greenboot-healthcheck finishes
the assessment and executes green or red scripts.

Possible, common scenarios that can get MicroShift into that state:
- Restart of microshift.service to reload the config
- Power loss or unexpected reboot of the machine before end of greenboot-healthcheck

To gracefully handle such scenarios, MicroShift will skip backup management
and proceed with the start up.

> Side note on non-first boots where `health.json` exists,
> but actions derived from its data were already performed:
>
> In case of microshift.service restart (e.g. to reload the config),
> it will re-attempt to perform the same actions it did on first start, for example:
> - `healthy`: back up the data - which won't happen, because backup already exists (not an error) 
> - `unhealthy`: attempt an "unhealthy system procedure" (described later).


#### Regular, expected in most cases, backup management procedure

##### *Boot ID stored in `health.json` matches current boot's ID: skip backup management and continue with start up

It means that information in `health.json` is intended for next boot
(be acted upon after system reboot) - it is a consequence of decision to
perform backup management on system boot.


##### `health.json` contains `healthy`

First, MicroShift will attempt to create a backup of the data named
with deployment and boot IDs from the `health.json`.

Then, if deployment ID stored in `health.json` differs from currently 
booted deployment's ID, it means different deployment was booted.

This can happen when:
- system is upgraded to a new deployment,
- system was rolled back,
- admin manually booted rollback deployment in grub menu.

To handle "going back to rollback deployment" scenario, MicroShift will check
the list of existing backups for one suitable for the currently booted deployment,
and, if found, it will restore that backup.
If no backup is found (e.g. upgrade), then MicroShift will continue start up.


##### `health.json` contains `unhealthy`

> Following steps might not be in the same order as implementation
> but should be functionally the same.

Summary:
- Try to restore backup for current deployment and continue start up
- If rollback deployment doesn't exist: continue start up
- Try to restore backup for rollback deployment and continue start up
- If there is no backup for neither the current nor rollback deployments:
  remove the data and continue start up (fresh)
- If `health.json` contains rollback deployment ID: exit with failure
- If `deployment_id` in `health.json` is neither current nor rollback deployments' ID:
  make "unhealthy" backup, remove the data and continue start up (fresh).

**If a backup for current deployment exists**: MicroShift will try to restore it and continue start up.

**If such backup does not exist**: MicroShift will try to restore backup for the rollback deployment.

**If rollback deployment does not exist** (i.e. there's only one deployment on the system):
it might be that system was manually rebooted or microshift.service manually restarted.
(It's not a reboot initiated by the greenboot because it only happens when `boot_counter` is set
and it's only set when deployment is staged.)
MicroShift will skip the backup management and continue with start up.

**If rollback deployment matches deployment ID persisted in the `health.json`**:
it means that it's an attempt to upgrade from unhealthy system which is unsupported -
if admin wants to perform such action, they should either get system to a healthy state,
or (if the MicroShift is the culprit) clear MicroShift data to start new
(and also get system to a healthy state).
In such case MicroShift will exit with an error that should render system unhealthy and eventually roll back.

> Extra comment:
>
> I think that on 2nd boot we'll lose that information resulting in different route:
> `health.json`.deployment_id == current deployment, health is `unhealthy`. 
> no backup to restore (neither current nor rollback deployment),
> so MicroShift will delete the data to start fresh.
> I think this might be confusing and unexpected (especially old data will be deleted).
> See [Test idea: upgrading from unhealthy system is blocked](#test-idea-upgrading-from-unhealthy-system-is-blocked)

**If deployment ID in `health.json` matches current deployment and backup for rollback deployment exists**:
restore and continue start up.
When upgrading the system fails during first boot of new deployement and renders system unhealthy,
on subsequent boots there is no backup for new deployment that could be restored.
Also, during subsequent boots MicroShift will consider the data unhealthy
(because that's the status in the `health.json`).

To gracefully handle such scenario, MicroShift will try to restore a backup
of the rollback deployment. This means that subsequent boots of new deployment
will have the same starting point as the first boot
(data belongs to previous deployment and is healthy).

> Extra comment:
> 
> This behaviour was previously designed so in case of failure to migrate the storage.
> It gives another chance to perform the migration starting from the initial state
> (that is starting with the data of previous deployment;
> starting just like it's first boot of new deployment).
>
> Since migration happens when full cluster is up and running,
> we might need to verify if this approach is still valid:
> - Does failure to migrate some CR will affect MicroShift's and in consequence system's health?

**If there is no backup for the rollback deployment**: remove the data and start fresh.
No backup of MicroShift data for rollback deployment might happen when rollback deployment
didn't feature MicroShift at all.
There is no backup to restore and current deployment is unhealthy -
we are not sure if MicroShift is the culprit, but being so early into
"MicroShift's lifetime" on the host we are not risking much when removing the data.
It's also a symmetrical with "restoring rollback deployment's backup"
where the data is restored so subsequent boots would start from the same point as first boot.

**If deployment ID in `health.json` doesn't match neither the rollback nor currently booted deployment**:
make an unhealthy backup and remove the data to allow for fresh start.


#### More details on backing up and restoring the data

Unhealthy backups were mentioned couple of times.
It must be noted that, when restoring the data, they are not considered a
candidates for the restore.

MicroShift will try its best to only keep one backup for particular deployment.
It means that before backing up, a list of backup for the deployment is obtained
and, after backing up, the list is used for deleting
"prior existing backups for the deployment that we
no longer need since we just backed up most up to date data".
This includes unhealthy backups.

If a particular backup (i.e. `deploymentID_bootID` combination),
there will be no new attempt to create a backup with that name again.
This is not considered an error - MicroShift will continue start up.

After successfully backing up the data, MicroShift compares list of
existing backups with deployments present on the system and removes any backup
which deployment is no longer present on the system.

### Version metadata management

TODO


### Migration

TODO

### Manual backup management (non-ostree)

TODO

# Test ideas

## Test idea: upgrading from unhealthy system is blocked

- System should roll back to "original" unhealthy deployment
- Greenboot should declare "system need manual intervention"
